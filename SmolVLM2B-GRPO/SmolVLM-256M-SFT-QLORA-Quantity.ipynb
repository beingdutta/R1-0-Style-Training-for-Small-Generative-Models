{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed9f1fe-5bb8-413c-b283-4caedf8b6d13",
   "metadata": {},
   "source": [
    "Ref:\n",
    "\n",
    "https://github.com/huggingface/smollm/blob/main/finetuning/Smol_VLM_FT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4050f-2a0e-4685-8f6f-8f707293bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import datasets\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405e372-9f87-4298-9376-71f245ed6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e2248-b330-4a03-bf48-d6198491b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"CONDA_DEFAULT_ENV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c77f9c-d7be-46cd-a1a9-ac761ffbb1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "432e7fa7-b9b2-4f9a-9517-fad347562c5f",
   "metadata": {},
   "source": [
    "### Set Up Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb53885-7b06-4758-a45a-e4d60f62f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear previous handlers to avoid duplicate logs in Jupyter\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Change to DEBUG for more verbosity\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]  # Ensures it logs to Jupyter cell output\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Logging is set up in the notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b34e4-5ade-4b26-9e06-7a7293aeaa56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc497182-14b1-4ac4-9331-d258b5e59a6e",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e34c5-cb23-471e-8a4a-c919bff96958",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dutta18/Quantity-Reasoning-VQA-23K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07108a74-6751-4ddb-86c8-a020cf56fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ec3cb-7799-48d4-bacd-ba66d464046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14baa471-7053-4945-a1fc-d5b4ce9dfde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1125c5d3-7838-475f-bee0-865d50454c99",
   "metadata": {},
   "source": [
    "### Load COT Think Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b784d-0633-4357-a068-70b48febe95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "think_data = list()\n",
    "\n",
    "with open('/home/aritrad/MOE-Directory/COT-Data-Qty-23K/Quantity-Reasoning-VQA-23K-Reasoning-Trace.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        record = json.loads(line)\n",
    "        think_data.append(record['generated_cot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273514eb-1976-49dc-921e-02a4c8841577",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(think_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766bc0c-7fb9-4998-9c55-ae9b84bd7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(think_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07600f1d-364a-42e5-a473-2672c1c1867c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2829558a-407a-4a73-a84a-17dc39791526",
   "metadata": {},
   "source": [
    "### Merge with Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87addb-d39c-4a99-8dd1-194ef231a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(\"cot_think_data\", think_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb1838-8119-4e21-b33d-8b2b57e70611",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9c0a8-9506-436e-ab6e-481ab3a5e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a single sample\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f4a04-0db9-4e24-8bdc-8fbab49e185f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72270b9c-390a-40de-bc06-c4e9146fb391",
   "metadata": {},
   "source": [
    "### Converting Output Number Words to Numeric Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320b4cd-3b41-42f1-8a75-b8ac85e9dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_map = {\n",
    "    \"zero\": 0, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4,\n",
    "    \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9,\n",
    "    \"ten\": 10, \"eleven\": 11, \"twelve\": 12, \"thirteen\": 13,\n",
    "    \"fourteen\": 14, \"fifteen\": 15, \"sixteen\": 16, \"seventeen\": 17,\n",
    "    \"eighteen\": 18, \"nineteen\": 19, \"twenty\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916ee70-2738-460c-a426-efcf5bbcb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_answer(example):\n",
    "    word = example[\"answer\"].strip().lower()\n",
    "    return {\"answer\": str(num_map.get(word, None))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22d12f-e9af-4a3e-9507-4e64cdab3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(convert_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe34752-3520-49ab-90e5-15849ccdb681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a single sample\n",
    "# Mismatch: 10, 100, 105, 600\n",
    "dataset[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca092c-eef9-4ae7-9da8-d5da1676cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0159c93-07d6-4ab7-9e24-151aa30e5bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d504441-4fce-4855-8a5d-b54f463137fb",
   "metadata": {},
   "source": [
    "### Rejection Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec701f9-d3f7-4448-bec8-ff31bb99fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Standardizes answers for comparison:\n",
    "    1. Lowers case.\n",
    "    2. Strips whitespace.\n",
    "    3. Removes trailing punctuation (like '6.' -> '6').\n",
    "    4. Converts word-numbers ('six') to digits ('6').\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Basic cleanup\n",
    "    text = str(text).strip().lower()\n",
    "    \n",
    "    # Remove trailing punctuation (e.g., \"6.\" -> \"6\")\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert number words to digits using the map\n",
    "    if text in num_map:\n",
    "        text = num_map[text]\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607811e-3bbf-4748-bacf-e613103d1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampling_filter(example):\n",
    "    \"\"\"\n",
    "    Returns True if the CoT answer matches the Ground Truth answer.\n",
    "    Returns False otherwise.\n",
    "    \"\"\"\n",
    "    ground_truth = example['answer']\n",
    "    cot_data = example['cot_think_data']\n",
    "    \n",
    "    # 1. Extract the answer from inside <answer> tags\n",
    "    # We use re.DOTALL to handle newlines, though usually answer is short\n",
    "    match = re.search(r\"<answer>(.*?)</answer>\", cot_data, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    # If no <answer> tag found, REJECT immediately\n",
    "    if not match:\n",
    "        return False\n",
    "        \n",
    "    generated_answer_content = match.group(1)\n",
    "    \n",
    "    # 2. Normalize both\n",
    "    norm_gt = normalize_text(ground_truth)\n",
    "    norm_gen = normalize_text(generated_answer_content)\n",
    "    \n",
    "    # 3. Compare\n",
    "    return norm_gt == norm_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567621e0-253e-40e1-ac6b-b95cddd41750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "print(f\"Original Dataset Size: {len(dataset)}\")\n",
    "\n",
    "# Apply the Rejection Sampling\n",
    "# load_from_cache_file=False ensures we re-run logic if we changed code\n",
    "filtered_dataset = dataset.filter(rejection_sampling_filter, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6bc5c-90c4-4de0-ba5f-f9d1abd40bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Statistics\n",
    "\n",
    "original_count = len(dataset)\n",
    "filtered_count = len(filtered_dataset)\n",
    "rejected_count = original_count - filtered_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01472eb-7228-49a9-a1fa-43baf264f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Rejection Sampling Results ---\\n\")\n",
    "print(f\"Original: {original_count}\")\n",
    "print(f\"Kept:     {filtered_count}\")\n",
    "print(f\"Rejected: {rejected_count}\")\n",
    "print(f\"Retention Rate: {(filtered_count/original_count)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2daf7-12a0-4dff-bfe0-5f73c2eba4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89558f-dead-4e6a-b9df-f1ff17f1a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c2862-2408-4b76-a20e-ceb5fff18d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae60a4b1-c7d8-44f5-9eb5-d79baa2f02ae",
   "metadata": {},
   "source": [
    "### Split Into Train, Test & Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f9070-3e4a-4d06-ae98-19c088f1162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ac896-8eab-46e4-8986-0749ec1a8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First create train (80%) and temp (20%)\n",
    "train_test = dataset.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# 2. Split the temp set into validation (10%) and test (10%)\n",
    "test_val = train_test['test'].train_test_split(test_size=0.6, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb8fa0-2f45-4e50-b720-3a42662cdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    'train': train_test['train'],\n",
    "    'validation': test_val['train'],\n",
    "    'test': test_val['test'],\n",
    "}\n",
    "\n",
    "dataset_dict = DatasetDict(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e71dde-5e46-4215-a9e5-60863cab1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = dataset_dict['train'], dataset_dict['validation'], dataset_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4d611-8f1d-48d9-a5cd-50c1cff74cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of the train set: {len(train_set)}, Val set: {len(val_set)} and Test Set: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c419f-e5d0-4df2-b47f-3697f538e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check A Particular Sample For Reproducibility\n",
    "\n",
    "print(train_set[100]['question'])\n",
    "print(val_set[100]['question'])\n",
    "print(test_set[100]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efacbca-cca1-4c24-942a-64343b559e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107fc53-b39f-4fe3-a557-8d0ef451d23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c693161-a8e2-4da5-9986-2c870ab56b60",
   "metadata": {},
   "source": [
    "### Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd22f3-174d-4ddf-844c-9ef45519b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import AutoModelForImageTextToText, BitsAndBytesConfig, Idefics3ForConditionalGeneration, AutoProcessor, AutoModelForVision2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87117fe7-e7d0-4b50-917d-aa46914d1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolVLM-256M-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1804c2-1966-44c5-ba98-b5014df87b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afaa27-8c63-41f4-9d6b-45c84430795f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b7a649-aac1-4aad-86e2-2370c5d78833",
   "metadata": {},
   "source": [
    "### Model Loading & Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a3c9f-d5dd-491c-94a0-e1c1e32a19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ed1d5-8342-4ac6-becd-0a8706b13266",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = bnb_config,\n",
    "    torch_dtype = torch.bfloat16, \n",
    "    _attn_implementation = \"flash_attention_2\",\n",
    "    device_map = 'cuda:0'\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f780d911-b405-42b1-bc47-0a2fb5135cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae6f7b0-5b2e-4f62-9d8d-152406a9d694",
   "metadata": {},
   "source": [
    "### LORA Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580517e-6ae0-4261-9fb5-b07bcc935363",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_everywhere = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc0777-8a16-4055-997f-6fc693cee6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=rank_everywhere,\n",
    "    lora_alpha=rank_everywhere*2,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[ 'k_proj', 'q_proj', 'v_proj', 'out_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'mlp.fc1', 'mlp.fc2'],\n",
    "    init_lora_weights=\"gaussian\",\n",
    "    inference_mode = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2329fc0-153b-44c2-b409-40b587b8f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlora_model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
    "qlora_model = get_peft_model(qlora_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fbfa07-65be-4bf0-b2e6-1ea5bb3a574a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba4e50f7-29dc-4c86-aee9-d53ef2edd83d",
   "metadata": {},
   "source": [
    "### Count Number of Params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02668013-a649-4bfa-b35e-8f26ec5e996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_trainable_params(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable params: {trainable/1e6:.1f} M\")\n",
    "\n",
    "report_trainable_params(qlora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a37ee-ab7c-4048-9b72-9fe3c11c5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f44822-4a49-4081-8eb8-61bb1f07d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_token_id = processor.tokenizer.additional_special_tokens_ids[processor.tokenizer.additional_special_tokens.index(\"<image>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a035b3-30b0-4d84-a4c5-80956bc9b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    texts = []\n",
    "    images = []\n",
    "\n",
    "    for example in examples:\n",
    "        image = example[\"image\"]\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\", \n",
    "                        \"text\": example[\"question\"]\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": example[\"cot_think_data\"]\n",
    "                }\n",
    "               ]\n",
    "            }\n",
    "        ]\n",
    "        text = processor.apply_chat_template(messages, add_generation_prompt=False)\n",
    "        texts.append(text.strip())\n",
    "        images.append([image])\n",
    "\n",
    "    # Batch using processor\n",
    "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # Manually set labels\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "    labels[labels == image_token_id] = -100\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    # Now cast pixel_values explicitly\n",
    "    batch[\"pixel_values\"] = batch[\"pixel_values\"].to(torch.bfloat16)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451915f-df5f-4e03-a083-3ad6ba071f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8c9def8-ade8-485f-8dfa-61bfdfc59c05",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709cb44-5415-4d53-950f-678765fc678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def do_validation():\n",
    "\n",
    "    qlora_model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(val_loader, desc=\"Validating\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = qlora_model(**batch)\n",
    "        loss = outputs[\"loss\"]\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    torch.cuda.empty_cache()\n",
    "    qlora_model.train()\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f2d985-6fe9-48e7-bd39-23b3275bdcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8f76b0e-6fa6-45d2-8914-1dbfb81c3207",
   "metadata": {},
   "source": [
    "### Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56c5e7-30f0-4723-b090-406e8549d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ = 4\n",
    "epochs = 5\n",
    "grad_accum_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9a1af-7058-41ea-a064-16e5f77fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc7c5f-b846-4261-87e3-7cac71e6339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(qlora_model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841aebfa-1a58-4195-b416-213aad21becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "best_val_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe981701-b41f-4501-b8f5-36bcac7aeda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = qlora_model.train()\n",
    "qlora_model.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca0b50-1c6e-4b7f-bff4-22b2611683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDir = '/home/aritrad/main/SmolVLM-2B/RL/chkpts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2ac93-cebf-4df4-8c8c-a6b2c67ea0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a4d32f0-6dcd-43d0-97e9-8637bf6b6e12",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26ec83-a7e2-4dbd-a6cb-1c2f85fbaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):  \n",
    "    \n",
    "    accumulated_loss = 0\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to('cuda:0') for k, v in batch.items()}\n",
    "        outputs = qlora_model(**batch)\n",
    "        loss = outputs[\"loss\"] / grad_accum_steps\n",
    "\n",
    "        loss.backward()\n",
    "        accumulated_loss += loss.item()\n",
    "        \n",
    "        if (idx + 1) % grad_accum_steps == 0: \n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "            logger.info(f\"[ Epoch {epoch+1} | idx: {idx} | Optim Step {global_step} | Train Loss: {loss.item():.4f} ]\")\n",
    "\n",
    "            if global_step % 10 == 0:\n",
    "                avg_val_loss = do_validation()\n",
    "                logger.info(f\"Val Loss @ Optim step: {global_step} -> {avg_val_loss:.4f}\\n\")\n",
    "            \n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    qlora_model.save_pretrained(os.path.join(saveDir, 'best-smolvlm-256M-qty-chkpt-32'))\n",
    "                    logger.info(f\"***** ✅ Checkpoint Saved *****\\n\")\n",
    "    \n",
    "    # StepLR Scheduler is updated at Last.\n",
    "    scheduler.step() \n",
    "    qlora_model.save_pretrained(os.path.join(saveDir, f'smolvlm-256M-qty-chkpt-{epoch+1}'))\n",
    "    logger.info(f\"***** ✅ Checkpoint Saved *****\\n\")\n",
    "    logger.info(f\"Epoch {epoch+1} completed. Avg loss: {accumulated_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328abd94-0f6c-460a-82da-85bc91cd6fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f1b3b-483d-4f91-bd1e-641243edd05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
