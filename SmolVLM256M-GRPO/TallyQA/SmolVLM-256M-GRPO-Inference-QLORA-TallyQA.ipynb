{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c37c2-4873-495a-93bf-61c5b5b8a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, re\n",
    "print(os.getenv(\"CONDA_DEFAULT_ENV\"))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e895bdc-cc0e-4d44-b872-049599d7f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import Image\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fcfc87-dcf6-4342-b398-0820954d2bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc69abe-d983-49d7-94c2-394a8e9f33f3",
   "metadata": {},
   "source": [
    "### Force Determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880c023-fbe4-4f00-9aec-199fa68247e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e35e5-edcd-41d6-8e58-1259f9ed20a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b16977d8-be07-4e49-8ac2-6a2e69d2d369",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36427284-674a-4885-86e7-fe7fbd4e1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/aritrad/tallyQA/test.json', 'r') as file:\n",
    "    test_set = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaca647-960c-4ab7-95d9-79c82034f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\", \n",
    "    data_files={ 'test': \"/home/aritrad/tallyQA/test.json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec86e94-d6e4-4b3e-9c15-dfcd8e0e9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of the Test Set: { len(dataset[\"test\"]) }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cba3f-e55f-4aa3-978a-58e0dab61543",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b3dfe-fbcf-46fc-bdde-0ed696308c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b9ff8-f761-45c9-8758-023c363193d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.remove_columns(['data_source', 'question_id', 'image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad18297-40c2-4d49-ac9f-99f5b82d4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_path = \"/home/aritrad/cric/visual_genome/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7544c8-6170-48a8-ba2b-2ac3322545d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_path(example):\n",
    "    # example[\"image\"] looks like \"VG_100K_2/1.jpg\"\n",
    "    filename = example[\"image\"].split(\"/\")[-1]   # \"1.jpg\"\n",
    "    new_path = f\"{base_image_path}/{filename}\"\n",
    "    example[\"image\"] = new_path\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e8dd8-b238-4c4b-9c4d-6b21442cb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.map(format_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be6001-7848-4aa0-aea6-f6c4f3c08674",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.cast_column(\"image\", Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6c334-fdd0-4a6d-b9fd-258ce66dfe80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c72911-2f90-4e42-b5cc-2abba4e7b5ec",
   "metadata": {},
   "source": [
    "### Filter out Complex Counting Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44936b3-c69c-4f04-be8f-d2e45013d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_filtered = test_set.filter(lambda x: x[\"issimple\"] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b73884-5439-49b9-96fa-106dcb51aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21d97f-f48d-4b49-8e6a-ac5edd5a1428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb576f32-4634-447f-b056-ec87d037e228",
   "metadata": {},
   "source": [
    "### Importing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395252b0-fee0-48e1-a867-a8468171dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f906b73-37d8-4b79-b89c-95216d307be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers.image_utils import load_image\n",
    "from transformers import AutoModelForImageTextToText, BitsAndBytesConfig, Idefics3ForConditionalGeneration, AutoProcessor, AutoModelForVision2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12383ba-ac67-4f8b-b503-f7a261857a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolVLM-256M-Instruct\"\n",
    "GRPO_finetuned_model_path = '/home/aritrad/main/SmolVLM-2B/RL/chkpts/chkpts_grpo/checkpoint-4000' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d325b-4c78-4469-b65f-e43629eebbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id, \n",
    "    dtype=torch.bfloat16, \n",
    "    _attn_implementation=\"flash_attention_2\",\n",
    "    device_map = 'auto',\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "processor.tokenizer.padding_side = \"left\"     # For batched generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5000a-41f6-4e13-b30b-fd1ae9ea1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the QLORA-trained model.\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, GRPO_finetuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ad6ae-903a-4b56-9809-452d455a62f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a73031ba-3bdf-4f78-a658-f839bf2a369e",
   "metadata": {},
   "source": [
    "### DECLARE SYSTEM PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae02dd4-eb9c-470f-8858-28166ed5b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The system prompt is extracted from DeepSeek R1 paper, modified for Quantity Reasoning\n",
    "SYSTEM_PROMPT = (\n",
    "    \"A conversation between User and Assistant. The user asks a question about an image, and the Assistant solves it. \" # <--- Added \"about an image\"\n",
    "    \"The assistant first thinks about the reasoning process by analyzing visual elements and then provides the user with \" # <--- Added \"analyzing visual elements\"\n",
    "    \"the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> \"\n",
    "    \"</answer> tags, respectively, i.e., \"\n",
    "    \"<think> reasoning process here </think><answer> answer here </answer>\\n\\n\"\n",
    "    \"Example:\\n\"\n",
    "    \"User: How many cats are in the image?\\n\"\n",
    "    \"Assistant: <think>\\n\"\n",
    "    \"1. Scanning the image, I see a black cat on the sofa.\\n\" # <--- \"Scanning the image\" reinforces vision\n",
    "    \"2. I also see a white cat under the table.\\n\"\n",
    "    \"Total count is 2.\\n\"\n",
    "    \"</think>\\n\"\n",
    "    \"<answer> 2 </answer>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508c92b-6063-4f41-9113-474105f76b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dff041-fb7b-406b-9174-2c5bf5456da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb2cad-97cf-4140-a046-38ba3bef7dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0141cc-7b2f-43cf-993c-5ba3257fc792",
   "metadata": {},
   "source": [
    "### Prepare Chat Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e443ab-c2dd-428b-8e8f-126e39a6f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    texts = []\n",
    "    images = []\n",
    "\n",
    "    for example in examples:\n",
    "        image = example[\"image\"]\n",
    "        \n",
    "        # 1. MERGE SYSTEM PROMPT (Matches your Training Setup)\n",
    "        # We inject the instructions directly into the User's text.\n",
    "        user_text = SYSTEM_PROMPT + \"\\n\\nQuestion: \" + example[\"question\"]\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": user_text}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # 2. GENERATE PROMPT WITH ASSISTANT HEADER\n",
    "        # add_generation_prompt=True ensures it ends with \"Assistant:\" (or equivalent)\n",
    "        text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "        \n",
    "        # 3. FORCE START (The \"Qwen\" Trick)\n",
    "        # We manually append the start tag. The model MUST continue from here.\n",
    "        text = text + \"<think>\\n1.\"\n",
    "        \n",
    "        texts.append(text.strip())\n",
    "        images.append([image])\n",
    "\n",
    "    # Batch using processor\n",
    "    # Note: Increase max_new_tokens in generate() later, 256 might be too short for thinking!\n",
    "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # Cast to bf16\n",
    "    batch[\"pixel_values\"] = batch[\"pixel_values\"].to(torch.bfloat16)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd04e7-b71f-4e0c-b333-a115b3cdc9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39663b85-a4ef-458e-a4b8-452cf852cab1",
   "metadata": {},
   "source": [
    "### Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1948e4c-6416-4e91-ae8b-4c47b2a67314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Dataloader.\n",
    "\n",
    "batch_ = 32\n",
    "test_loader = DataLoader(test_set, batch_size=batch_, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d635982-5c11-4260-849a-a562823b79c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6054c9c-dfa1-472e-8832-307f0622d057",
   "metadata": {},
   "source": [
    "### Generate Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1c0a9-bc1f-47cd-a057-e24671a2319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_outputs=list()\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    \n",
    "    batch = {key: value.to('cuda') for key, value in batch.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = peft_model.generate(\n",
    "            **batch, \n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,                # enable sampling\n",
    "            temperature=0.6,               # randomness factor\n",
    "            num_return_sequences=1,\n",
    "            repetition_penalty=1.05,       # Slight penalty to prevent <think><think> loops\n",
    "        )\n",
    "        model_generated_output_only = outputs[:, batch[\"input_ids\"].shape[-1]:]\n",
    "        decoded_output = processor.batch_decode(\n",
    "            model_generated_output_only, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        decoded_outputs.extend(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8ae1c-20e4-426c-af3e-99ca2d77ae45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144660a-12e3-48c2-aff8-7e397b8307e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('<think>\\n1.' + decoded_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7f333-0fad-4f3a-8c8a-c3a25cb09d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f0b749e-4f6d-4aad-a514-9b95b7d7af0f",
   "metadata": {},
   "source": [
    "### Manual Addition of < think > tokens to Generated Outputs ( Added Force-Tokens )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a137e9-4dc9-438a-a2dc-62a674e8c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_outputs = ['<think>\\n1.' + decoded_outputs[i] for i in range(len(decoded_outputs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebaf9f4-fd48-4530-aa7b-3e34de3d1a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91d4c519-06fc-40e0-98a2-647b71c645f5",
   "metadata": {},
   "source": [
    "### Manual Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd13bd6-2f74-4620-a021-0a250005debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print(decoded_outputs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa26f95-566a-48e8-8c6a-de1d8f64229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set_filtered[idx]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c1908-d830-4ead-8ef8-317454853785",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_set_filtered[idx]['image']\n",
    "image.thumbnail((400, 800))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af466a25-8fd0-449b-a841-95f5b8cbae41",
   "metadata": {},
   "source": [
    "### End of Manual Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c4fca-48ab-4df8-b129-4776c35eac97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba4d38b0-d19c-4341-98be-91e989738176",
   "metadata": {},
   "source": [
    "### Parsing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d4ef6-c1f5-44d9-87ea-373f0dd69418",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_outputs = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ff810-9390-4db4-bd5d-c1b53c850d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_clean_trace(rawOutputs, outputList):\n",
    "\n",
    "    for response_text in rawOutputs:\n",
    "\n",
    "        try:\n",
    "            thought_part = response_text.split('<think>')[1].strip().split(\"</think>\")[0].strip()\n",
    "            answer_part = response_text.split(\"<answer>\")[1].split(\"</answer>\")[0].strip()\n",
    "    \n",
    "            outputList.append( (thought_part, answer_part) )\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            # Poor Formatted Outputs\n",
    "            outputList.append( ('NULL', 'NULL') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54d39f-c341-4b9f-9465-4d0e7c00a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_clean_trace(decoded_outputs, generated_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c27e56-ec4e-4c74-9c31-2d34e32ed140",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruthAnswer = test_set_filtered['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e6999-9fb7-4fac-9759-07252ab4d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generated_outputs), len(groundTruthAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb7471-1932-40f3-98fb-e12b958f3a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880df74d-743d-4ee4-877a-9c05d7d8abf4",
   "metadata": {},
   "source": [
    "### Calculate Proper Formatted Output Percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf195d-6fa3-4826-ad5c-5c74a0d1528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFormattedOutputPercent(targetList):\n",
    "    count = 0\n",
    "    for item in targetList:\n",
    "        if item[0]=='NULL':\n",
    "            count += 1\n",
    "\n",
    "    return ((len(targetList)-count)/len(targetList))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f20a7-2d30-4c92-8c9e-9d8c193ce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateFormattedOutputPercent(decoded_ouputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3a42d-936f-41a8-8903-77b64e9bd582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16e3f0df-0cc0-4ce0-b90d-97dffdb7eca6",
   "metadata": {},
   "source": [
    "### Cosine Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb5df4-5c83-4f9b-b8b2-d08de72ad63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sbert = SentenceTransformer('all-mpnet-base-v2', device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3718b1-e627-4466-bd13-0dbc0586f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosSim(word1:str, word2:str) -> int:\n",
    "\n",
    "    # Compute the embeddings\n",
    "    embedding1 = sbert.encode(word1, convert_to_tensor=True)\n",
    "    embedding2 = sbert.encode(word2, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return round(cosine_score.item(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c463928c-ac93-4539-ad3e-f2a90d444e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33c3d83e-111a-4efc-8ccd-fb4b41a259e8",
   "metadata": {},
   "source": [
    "### Accuracy - Short Answers¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0fd6d-b4e9-4a59-a83f-fd3065dc1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_ouputs_short_answers = [decoded_ouputs[idx][1] for idx in range(len(generated_outputs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b92bbe-6e16-4ec9-8141-aee6e818d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruth_outputs_short_answers = [ str(groundTruthAnswer[idx]) for idx in range(len(groundTruthAnswer))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882fc180-6810-4884-baaa-b3e7253308d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruth_outputs_short_answers[500:505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bdf57-32cc-4c97-913b-a1634ea84405",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_ouputs_short_answers[500:505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60170371-e071-482a-b24a-419b4c884531",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ( sum([ 1 if groundTruth_outputs_short_answers[i].strip()==decoded_ouputs_short_answers[i].strip() else 0 for i in range(len(decoded_ouputs)) ]) / len(decoded_ouputs) ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af8b6b-30cc-4510-80db-ca2ed2c63d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Final Short Answer Accuracy: {round(accuracy, 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54a681-53e1-48b0-970a-f73a35ea2a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b306a04-b34e-4bf8-92ce-16d64f6864aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be1e3f83-f433-4171-b494-4be6974cbdbb",
   "metadata": {},
   "source": [
    "### Check Umatched Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13bcd1f-b894-452c-a0b2-f5abe120e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_indices = [\n",
    "    idx\n",
    "    for idx in range(len(groundTruth_outputs_short_answers))\n",
    "    if groundTruth_outputs_short_answers[idx].strip() != decoded_ouputs_short_answers[idx].strip()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049deaf-a243-443c-b2d2-a11d70655e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_indices[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfbd02-8350-40e1-b8f7-6a08c2894406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9cb2f-d2e4-4550-85d4-33e411cfe368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13bb268-fed9-4c2a-bf2f-a6b2e55595a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320604fb-25fb-4a32-ade9-1430c6a78c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"<think>\\nThe user asked\" + resultGeneratedAnswers[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78eb4b-bdc9-4956-b845-733b34a9a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Q:', test_set_filtered[idx]['question'],'\\n\\nA:', test_set_filtered[idx]['answer'], '\\n\\nidx:', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb606ac-9f50-48c9-ab71-58187d169d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_filtered[idx]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410c327-eef0-427a-bcf8-54326c5114e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
