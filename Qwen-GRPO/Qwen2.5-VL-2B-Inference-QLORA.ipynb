{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df414fd-5123-411b-bf11-2110d9c5ca38",
   "metadata": {},
   "source": [
    "Ref:\n",
    "\n",
    "Batch Inference Section: https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b549ed-ffed-468b-b45e-b7e4ed19a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "print(os.getenv(\"CONDA_DEFAULT_ENV\"))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d589a76-3089-4028-882e-3ee79ecc92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import datasets\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df87b6-d50a-41cb-90da-e5c10b9ce96d",
   "metadata": {},
   "source": [
    "### Force Determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88826b1e-b971-47e0-9f74-f8c1eb58cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839288bf-7240-45ac-abf6-06c5cca34263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32f4dcec-10af-412b-a538-c196ba4c53b9",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92744a73-bdb0-4fcd-bc32-37d182599200",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dutta18/Quantity-Reasoning-VQA-23K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9167a7-5ab0-4495-bec4-2dbc3cadace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1717f04a-6d9b-4405-8d9c-34413ad2f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bd66e-46b0-4d39-92b1-1ae4699b5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(4450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51caf1df-1046-4b14-a8c6-ddcae875797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd899c0f-c656-4e17-be44-7b10598ac628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1236a36-fe15-4350-bc11-d285e2716e7e",
   "metadata": {},
   "source": [
    "### Load COT Think Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389abf3-c967-4be7-a401-2d701d342a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./qty-reasoning-cot-data-8000.pkl', 'rb') as file:\n",
    "    cot_think_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c53c1-9821-4d40-849a-1bdfbdc28aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_think_data = cot_think_data[:4450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e80b35-fb35-4b80-a0df-ffef267dc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(\"cot_think_data\", cot_think_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072230a-644f-43c1-a687-2be6c0686efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974bb2a-24e8-4a64-bf24-ea4ffff99e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e69bb27-6d19-4c3f-bd63-5acbf7e249ee",
   "metadata": {},
   "source": [
    "### Split Into Train, Test & Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16aa50-bf00-4fcc-85a4-eb20b4c2ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0231d01-04de-4001-8ce9-6ab0a0b8285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First create train (80%) and temp (20%)\n",
    "train_test = dataset.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# 2. Split the temp set into validation (10%) and test (10%)\n",
    "test_val = train_test['test'].train_test_split(test_size=0.6, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b146d0-d249-41d1-8654-bfa2519744a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    'train': train_test['train'],\n",
    "    'validation': test_val['train'],\n",
    "    'test': test_val['test'],\n",
    "}\n",
    "\n",
    "dataset_dict = DatasetDict(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9a026-bc6a-4723-a9f5-87d15231301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = dataset_dict['train'], dataset_dict['validation'], dataset_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3f675-efe7-4e8c-85d0-aef4c7bafd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d617c0-84c9-4e1e-8247-c9baf620c371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f518024-45fd-421c-8db9-963b451e64df",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74994037-c80f-4083-b06a-d27098d5ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from util.vision_util import process_vision_info\n",
    "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a060d5-06ee-48df-9d5f-cfd36eab3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_base_model_path = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "QLORA_finetuned_model_path = '/home/aritrad/main/Qwen2.5-VL-3B/GRPO/chkpts/qwen2.5-qty-chkpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c27da-bfa6-4020-acd0-52ad5e4ac37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage = True,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Load processor. \n",
    "# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\", \n",
    "    min_pixels=256*28*28, \n",
    "    max_pixels=512*28*28, \n",
    "    padding_side=\"left\",\n",
    "    use_fast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f14fa6-e7bc-4c11-a0fe-df3066c111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the QLORA-Trained Model.\n",
    "\n",
    "peft_trained_model = PeftModel.from_pretrained(model, QLORA_finetuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bad8f-982c-4ece-beea-acf02dcb3cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e6a712-b168-4638-a74e-9087fae0aca8",
   "metadata": {},
   "source": [
    "### Prepare Chat Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc851c20-d389-49cd-b316-8f0d2e989b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "messageList = list()\n",
    "\n",
    "for i in tqdm(range(len(test_set))):\n",
    "    \n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\", \n",
    "                    \"image\": test_set[i]['image']\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": test_set[i]['question']\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messageList.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93969ea-59bb-457a-b8a1-058cfcdcf937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size.\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dee30-1e0d-41ac-8df2-c544f84e30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset in batches.\n",
    "resultGeneratedAnswers = list()\n",
    "\n",
    "for i in tqdm(range(0, len(messageList), batch_size)):\n",
    "    \n",
    "    # Slice the dataset for the current batch\n",
    "    messageBatch = messageList[i:i + batch_size]\n",
    "\n",
    "    # Preparation for batch inference\n",
    "    texts = [\n",
    "        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n",
    "        for msg in messageBatch\n",
    "    ]\n",
    "    image_inputs, video_inputs = process_vision_info(messageBatch)\n",
    "    inputs = processor(\n",
    "        text=texts,\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "\n",
    "    # Batch Inference\n",
    "    generated_ids = peft_trained_model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=256,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "        \n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_texts = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    #print(output_texts, '\\n\\n')\n",
    "    resultGeneratedAnswers.extend(output_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1861e-3eba-4881-82e7-1bda18812008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultGeneratedAnswers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797b6ba-2cbc-4a05-844f-f11c7cd4808e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c3be-9042-4192-a990-04e64d66eb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0fe1be8-d4b6-4394-b5d5-13b43619b483",
   "metadata": {},
   "source": [
    "### Manual Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd134ead-67f9-4368-bc82-3745007c4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resultGeneratedAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87d3af-0a77-4945-a71d-d1a854c2f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7383a0-e6c7-4090-b3fb-5bae282d2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set[idx]['question'],'\\n\\n', test_set[idx]['answer'],'\\n\\n', test_set[idx]['cot_think_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cac80-1452-4f9c-a9cd-e8e92c37ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultGeneratedAnswers[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c91544-5860-436f-9cfb-e26e2c180db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[idx]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5f02b-399c-4074-aa09-b5a81c3f7f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bafa38e8-94f1-490c-939b-f651efccb3f4",
   "metadata": {},
   "source": [
    "### Parsing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8968328-3a23-44bd-93ee-4713b29d10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_ouputs = resultGeneratedAnswers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd38e3b-25ac-4d03-b07f-21707574a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "COT_generated, shortAnswers_generated = [], []\n",
    "\n",
    "for i in range(len(decoded_ouputs)):\n",
    "    try:\n",
    "        CoTAnswer, shortAnswer = decoded_ouputs[i].split('Final Answer:')\n",
    "        COT_generated.append(CoTAnswer.strip()); shortAnswers_generated.append(shortAnswer.lower().strip().replace('.', ''))\n",
    "    except:\n",
    "        #print(i)\n",
    "        COT_generated.append('NULL'); shortAnswers_generated.append('NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fd5ab-95a1-4b9d-8b6e-80bf6e288608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT Labels:\n",
    "\n",
    "shortAnswers_groundTruth = val_set['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b4391-4f56-49d5-b574-d385add18753",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(COT_generated), len(shortAnswers_generated), len(shortAnswers_groundTruth), len(COT_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b9e0ae-e10f-4c26-9925-cb7eb9f3bb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee14d200-5625-460e-bf2a-80e19c370b3f",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf6f15-2d80-43cd-99b3-9ec66593014e",
   "metadata": {},
   "source": [
    "### Reasoning Group wise Exact Match (GEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8ae33-2cdb-4439-b361-bbaf24b00e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211da03-7e98-4902-9efa-821c9520bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_counts = defaultdict(int)\n",
    "total_counts = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78210692-63c0-49c4-99f6-87209bf65ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt, pred, rtype in zip(val_set['answer'], shortAnswers_generated, val_set['reasoning_type']):\n",
    "    total_counts[rtype] += 1\n",
    "    if pred.strip().lower() == gt.strip().lower():\n",
    "        match_counts[rtype] += 1\n",
    "\n",
    "accuracy_per_type = {\n",
    "    rtype: match_counts[rtype] / total_counts[rtype]\n",
    "    for rtype in total_counts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e5a17-35ab-47ed-a47a-94c2830c7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rtype, acc in accuracy_per_type.items():\n",
    "    print(f\"{rtype.capitalize()}: {acc:.2%} ({match_counts[rtype]}/{total_counts[rtype]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c082f77-1f45-4547-9827-08c42dead500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "554d0014-4412-4741-aac2-69422ae7393c",
   "metadata": {},
   "source": [
    "### Evaluate Exact String Match (EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7f35a-39c4-4d95-87c8-f0ded9d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for accuracy calculation\n",
    "correct_predictions = 0\n",
    "total_predictions = len(shortAnswers_generated)\n",
    "\n",
    "# Loop through the results and compare answers\n",
    "for i in range(len(shortAnswers_generated)):\n",
    "    if shortAnswers_generated[i].strip().lower() == shortAnswers_groundTruth[i].strip().lower():\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae001ad-1b6e-455d-a777-7c9fbe7dcd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6baddc55-88fd-40e3-b97d-281a1de293e9",
   "metadata": {},
   "source": [
    "## Evaluating with BERT Score\n",
    "\r\n",
    "Precision (P): How much of the candidate's content is relevant.\r\n",
    "\r\n",
    "Recall (R): How much of the reference's content is covered by the candidate.\r\n",
    "\r\n",
    "F1 Score (F1): Harmonic mean of Precision and Recall, commonly used as the final metric.al metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f4c09-b8ef-4536-8d54-28578a66c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Example references and candidates\n",
    "# references = ['stool','no','person','stool','sign','bronze','door','no','red','chair','red','black']\n",
    "# candidates = ['stool','no','child','stool','sign','gold','picture','no','brown','chair','brown','black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb6fc9-33bf-40f6-b8e9-2d30e3979cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BERTScore, answerList_test = ground truth, result_list = model generated\n",
    "P, R, F1 = score(COT_generated, COT_groundtruth, lang=\"en\", verbose=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ceb90d-60d4-46f5-8297-ac47bbe4e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print scores\n",
    "print(\"Mean Precision:\", np.round(np.mean(P.tolist())*100, 2) )\n",
    "print(\"Mean Recall:\", np.round(np.mean(R.tolist())*100, 2) )\n",
    "print(\"Mean F1 Score:\", np.round(np.mean(F1.tolist())*100, 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a0951-fd5c-4030-a031-69a818a163ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0155817-2c3e-4cd2-a0ff-176155f8d443",
   "metadata": {},
   "source": [
    "### Evaluating with BLEU-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606baee7-ea7a-4ba2-92eb-f2fc800d43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8ea5c-3c4e-4d81-a036-754c5dd3ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "\n",
    "# Function to compute BLEU-1 score for a list of ground truth and predicted answers\n",
    "def calculate_bleu_1_score(ground_truth, predicted):\n",
    "\n",
    "    # This sets BLEU-1 to only consider unigram precision\n",
    "    weights = [1.0] + [0.0] * 3  \n",
    "    \n",
    "    # Smoothing function to handle cases with no n-gram matches\n",
    "    smoothing_function = SmoothingFunction().method1  \n",
    "    \n",
    "    for gt, pred in zip(ground_truth, predicted):\n",
    "        score = sentence_bleu([gt], pred, weights=weights, smoothing_function=smoothing_function)  \n",
    "        bleu_scores.append(score)\n",
    "    \n",
    "    avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "    \n",
    "    return avg_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71b6f5-1d1d-415d-b131-22afdc9a811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the BLEU score\n",
    "avg_bleu = calculate_bleu_1_score(COT_generated, COT_groundtruth)\n",
    "print(f\"Average BLEU score: {np.round(avg_bleu*100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74a577-0b4d-419a-b61c-46ef63e436bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "618c6891-c1c4-4f8e-abb7-37f286e337fc",
   "metadata": {},
   "source": [
    "### ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f300df-0fee-4dc9-be8d-feb6871b5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42592044-d29e-410c-9db5-568ed306a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_rouge_scores(references, candidates):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n",
    "\n",
    "    for ref, cand in zip(references, candidates):\n",
    "        scores = scorer.score(ref, cand)\n",
    "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "\n",
    "    return {\n",
    "        \"ROUGE-1\": np.round(np.mean(rouge1_scores), 4),\n",
    "        \"ROUGE-2\": np.round(np.mean(rouge2_scores), 4),\n",
    "        \"ROUGE-L\": np.round(np.mean(rougeL_scores), 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445023d7-f15e-488b-91ef-83f0b89c9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rouge = calculate_avg_rouge_scores(COT_generated, COT_groundtruth)\n",
    "avg_rouge = { k:round(v*100, 2) for k,v in avg_rouge.items()}\n",
    "print(\"Average ROUGE scores:\", avg_rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e0544-8f29-4c48-9bb3-0b3635f80284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e2e8355-3f3e-4dea-8efa-d3dc3065217d",
   "metadata": {},
   "source": [
    "### Cosine Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da3cad-0ae6-4fe3-a10f-5cb9878cfc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sbert = SentenceTransformer('all-mpnet-base-v2', device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7a9cc-a678-4d02-b020-cc6c16147922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosSim(word1:str, word2:str) -> int:\n",
    "\n",
    "    # Compute the embeddings\n",
    "    embedding1 = sbert.encode(word1, convert_to_tensor=True)\n",
    "    embedding2 = sbert.encode(word2, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return round(cosine_score.item(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780efab-4300-4085-aa5e-9e5b4a778dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fc37c0d-e7de-460a-aed6-c62c10521524",
   "metadata": {},
   "source": [
    "### Cosine Accuracy - COT Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972148e7-1028-4db0-a827-e1becfed6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "COTCosineAccuracy = []\n",
    "\n",
    "for idx in tqdm(range(len(COT_generated))):\n",
    "    if COT_generated[idx] == 'NULL':\n",
    "        # print('0')\n",
    "        score = 0\n",
    "    else:\n",
    "        cos_sim = findCosSim(COT_generated[idx], COT_groundtruth[idx])\n",
    "        if cos_sim > 0.8:\n",
    "            score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "    \n",
    "    COTCosineAccuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aec040-6d13-45c3-8ea9-973e8a3d6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "round( ( sum(COTCosineAccuracy) / len(COTCosineAccuracy) ) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73dbfb5-5235-47be-824e-d93acad2d3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1633ecf5-1260-4f41-9aef-7cb1ce32a09c",
   "metadata": {},
   "source": [
    "### Cosine Accuracy - Short Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746df2e-b269-47f5-823d-d22bbdcc7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosineAccuracy = [ findCosSim( shortAnswers_generated[idx], shortAnswers_groundTruth[idx] ) > 0.71 for idx in tqdm(range(len(shortAnswers_groundTruth))) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e36c1-7138-437b-b1b9-c639621f41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "round( ( sum(cosineAccuracy) / len(cosineAccuracy) ) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f9306-c164-4d45-b411-a2587822c06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa97dd1-4116-49c1-b04e-ca5ad228de1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
